{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Hand_Sign_Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZjsHTSWOfbc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYpGc1T9LPus",
        "outputId": "af315396-e0ae-4470-a4d8-da30a7f54b24"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Grnhsu-GOr5y"
      },
      "source": [
        "#load data\n",
        "data_test=pd.read_csv(\"https://raw.githubusercontent.com/VinitaSilaparasetty/hand-gesture-recognition/main/sign_mnist_test.csv\")\n",
        "data_train=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Datasets/sign_mnist_train.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3y80HnlJiKK"
      },
      "source": [
        "def show_img(img, df):\n",
        "    label = df['label'][img]\n",
        "    pixels = df.iloc[img, 1:]\n",
        "    pixels = np.array(pixels, dtype='uint8')\n",
        "    pixels = pixels.reshape((28, 28))\n",
        "\n",
        "    plt.title(f'Label is {label}')\n",
        "    plt.imshow(pixels, cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "IxlT2PQCVZd6",
        "outputId": "c296fbb4-56b9-4b87-8eab-84db1b6d2906"
      },
      "source": [
        "show_img(20, data_train)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "w0Hh6ef1KySr",
        "outputId": "94c0102a-d6a7-42ed-a4c5-1f916e5c9113"
      },
      "source": [
        "data_test.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>149</td>\n",
              "      <td>149</td>\n",
              "      <td>150</td>\n",
              "      <td>150</td>\n",
              "      <td>150</td>\n",
              "      <td>151</td>\n",
              "      <td>151</td>\n",
              "      <td>150</td>\n",
              "      <td>151</td>\n",
              "      <td>152</td>\n",
              "      <td>152</td>\n",
              "      <td>152</td>\n",
              "      <td>152</td>\n",
              "      <td>152</td>\n",
              "      <td>153</td>\n",
              "      <td>153</td>\n",
              "      <td>151</td>\n",
              "      <td>152</td>\n",
              "      <td>152</td>\n",
              "      <td>153</td>\n",
              "      <td>152</td>\n",
              "      <td>152</td>\n",
              "      <td>151</td>\n",
              "      <td>151</td>\n",
              "      <td>150</td>\n",
              "      <td>150</td>\n",
              "      <td>150</td>\n",
              "      <td>149</td>\n",
              "      <td>150</td>\n",
              "      <td>150</td>\n",
              "      <td>150</td>\n",
              "      <td>152</td>\n",
              "      <td>152</td>\n",
              "      <td>151</td>\n",
              "      <td>152</td>\n",
              "      <td>152</td>\n",
              "      <td>152</td>\n",
              "      <td>152</td>\n",
              "      <td>152</td>\n",
              "      <td>...</td>\n",
              "      <td>131</td>\n",
              "      <td>134</td>\n",
              "      <td>144</td>\n",
              "      <td>147</td>\n",
              "      <td>125</td>\n",
              "      <td>87</td>\n",
              "      <td>87</td>\n",
              "      <td>103</td>\n",
              "      <td>107</td>\n",
              "      <td>110</td>\n",
              "      <td>116</td>\n",
              "      <td>113</td>\n",
              "      <td>75</td>\n",
              "      <td>74</td>\n",
              "      <td>74</td>\n",
              "      <td>74</td>\n",
              "      <td>76</td>\n",
              "      <td>74</td>\n",
              "      <td>82</td>\n",
              "      <td>134</td>\n",
              "      <td>168</td>\n",
              "      <td>155</td>\n",
              "      <td>146</td>\n",
              "      <td>137</td>\n",
              "      <td>145</td>\n",
              "      <td>146</td>\n",
              "      <td>149</td>\n",
              "      <td>135</td>\n",
              "      <td>124</td>\n",
              "      <td>125</td>\n",
              "      <td>138</td>\n",
              "      <td>148</td>\n",
              "      <td>127</td>\n",
              "      <td>89</td>\n",
              "      <td>82</td>\n",
              "      <td>96</td>\n",
              "      <td>106</td>\n",
              "      <td>112</td>\n",
              "      <td>120</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>126</td>\n",
              "      <td>128</td>\n",
              "      <td>131</td>\n",
              "      <td>132</td>\n",
              "      <td>133</td>\n",
              "      <td>134</td>\n",
              "      <td>135</td>\n",
              "      <td>135</td>\n",
              "      <td>136</td>\n",
              "      <td>138</td>\n",
              "      <td>137</td>\n",
              "      <td>137</td>\n",
              "      <td>138</td>\n",
              "      <td>138</td>\n",
              "      <td>139</td>\n",
              "      <td>137</td>\n",
              "      <td>142</td>\n",
              "      <td>140</td>\n",
              "      <td>138</td>\n",
              "      <td>139</td>\n",
              "      <td>137</td>\n",
              "      <td>137</td>\n",
              "      <td>136</td>\n",
              "      <td>135</td>\n",
              "      <td>134</td>\n",
              "      <td>133</td>\n",
              "      <td>134</td>\n",
              "      <td>132</td>\n",
              "      <td>129</td>\n",
              "      <td>132</td>\n",
              "      <td>134</td>\n",
              "      <td>135</td>\n",
              "      <td>135</td>\n",
              "      <td>137</td>\n",
              "      <td>139</td>\n",
              "      <td>139</td>\n",
              "      <td>139</td>\n",
              "      <td>140</td>\n",
              "      <td>141</td>\n",
              "      <td>...</td>\n",
              "      <td>114</td>\n",
              "      <td>112</td>\n",
              "      <td>89</td>\n",
              "      <td>48</td>\n",
              "      <td>133</td>\n",
              "      <td>194</td>\n",
              "      <td>182</td>\n",
              "      <td>185</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>182</td>\n",
              "      <td>181</td>\n",
              "      <td>172</td>\n",
              "      <td>174</td>\n",
              "      <td>177</td>\n",
              "      <td>178</td>\n",
              "      <td>178</td>\n",
              "      <td>179</td>\n",
              "      <td>181</td>\n",
              "      <td>183</td>\n",
              "      <td>187</td>\n",
              "      <td>175</td>\n",
              "      <td>165</td>\n",
              "      <td>154</td>\n",
              "      <td>118</td>\n",
              "      <td>107</td>\n",
              "      <td>100</td>\n",
              "      <td>75</td>\n",
              "      <td>96</td>\n",
              "      <td>83</td>\n",
              "      <td>47</td>\n",
              "      <td>104</td>\n",
              "      <td>194</td>\n",
              "      <td>183</td>\n",
              "      <td>186</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>184</td>\n",
              "      <td>182</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>85</td>\n",
              "      <td>88</td>\n",
              "      <td>92</td>\n",
              "      <td>96</td>\n",
              "      <td>105</td>\n",
              "      <td>123</td>\n",
              "      <td>135</td>\n",
              "      <td>143</td>\n",
              "      <td>147</td>\n",
              "      <td>152</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>168</td>\n",
              "      <td>171</td>\n",
              "      <td>182</td>\n",
              "      <td>172</td>\n",
              "      <td>175</td>\n",
              "      <td>185</td>\n",
              "      <td>183</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>183</td>\n",
              "      <td>183</td>\n",
              "      <td>182</td>\n",
              "      <td>181</td>\n",
              "      <td>178</td>\n",
              "      <td>86</td>\n",
              "      <td>88</td>\n",
              "      <td>93</td>\n",
              "      <td>96</td>\n",
              "      <td>108</td>\n",
              "      <td>125</td>\n",
              "      <td>137</td>\n",
              "      <td>145</td>\n",
              "      <td>149</td>\n",
              "      <td>154</td>\n",
              "      <td>160</td>\n",
              "      <td>...</td>\n",
              "      <td>145</td>\n",
              "      <td>123</td>\n",
              "      <td>78</td>\n",
              "      <td>162</td>\n",
              "      <td>239</td>\n",
              "      <td>227</td>\n",
              "      <td>229</td>\n",
              "      <td>226</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>224</td>\n",
              "      <td>222</td>\n",
              "      <td>89</td>\n",
              "      <td>91</td>\n",
              "      <td>94</td>\n",
              "      <td>111</td>\n",
              "      <td>136</td>\n",
              "      <td>154</td>\n",
              "      <td>167</td>\n",
              "      <td>184</td>\n",
              "      <td>125</td>\n",
              "      <td>3</td>\n",
              "      <td>166</td>\n",
              "      <td>225</td>\n",
              "      <td>195</td>\n",
              "      <td>188</td>\n",
              "      <td>172</td>\n",
              "      <td>185</td>\n",
              "      <td>161</td>\n",
              "      <td>122</td>\n",
              "      <td>68</td>\n",
              "      <td>166</td>\n",
              "      <td>242</td>\n",
              "      <td>227</td>\n",
              "      <td>230</td>\n",
              "      <td>227</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>224</td>\n",
              "      <td>222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>203</td>\n",
              "      <td>205</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>207</td>\n",
              "      <td>209</td>\n",
              "      <td>210</td>\n",
              "      <td>209</td>\n",
              "      <td>210</td>\n",
              "      <td>209</td>\n",
              "      <td>208</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>209</td>\n",
              "      <td>208</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>207</td>\n",
              "      <td>209</td>\n",
              "      <td>209</td>\n",
              "      <td>208</td>\n",
              "      <td>209</td>\n",
              "      <td>210</td>\n",
              "      <td>209</td>\n",
              "      <td>207</td>\n",
              "      <td>208</td>\n",
              "      <td>209</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>208</td>\n",
              "      <td>209</td>\n",
              "      <td>208</td>\n",
              "      <td>208</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>209</td>\n",
              "      <td>209</td>\n",
              "      <td>...</td>\n",
              "      <td>85</td>\n",
              "      <td>80</td>\n",
              "      <td>84</td>\n",
              "      <td>151</td>\n",
              "      <td>238</td>\n",
              "      <td>255</td>\n",
              "      <td>255</td>\n",
              "      <td>250</td>\n",
              "      <td>237</td>\n",
              "      <td>245</td>\n",
              "      <td>250</td>\n",
              "      <td>232</td>\n",
              "      <td>103</td>\n",
              "      <td>101</td>\n",
              "      <td>102</td>\n",
              "      <td>103</td>\n",
              "      <td>95</td>\n",
              "      <td>208</td>\n",
              "      <td>231</td>\n",
              "      <td>227</td>\n",
              "      <td>209</td>\n",
              "      <td>190</td>\n",
              "      <td>179</td>\n",
              "      <td>182</td>\n",
              "      <td>152</td>\n",
              "      <td>150</td>\n",
              "      <td>159</td>\n",
              "      <td>119</td>\n",
              "      <td>83</td>\n",
              "      <td>63</td>\n",
              "      <td>154</td>\n",
              "      <td>248</td>\n",
              "      <td>247</td>\n",
              "      <td>248</td>\n",
              "      <td>253</td>\n",
              "      <td>236</td>\n",
              "      <td>230</td>\n",
              "      <td>240</td>\n",
              "      <td>253</td>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>188</td>\n",
              "      <td>191</td>\n",
              "      <td>193</td>\n",
              "      <td>195</td>\n",
              "      <td>199</td>\n",
              "      <td>201</td>\n",
              "      <td>202</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>203</td>\n",
              "      <td>204</td>\n",
              "      <td>204</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "      <td>198</td>\n",
              "      <td>216</td>\n",
              "      <td>217</td>\n",
              "      <td>135</td>\n",
              "      <td>181</td>\n",
              "      <td>200</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>193</td>\n",
              "      <td>190</td>\n",
              "      <td>189</td>\n",
              "      <td>187</td>\n",
              "      <td>185</td>\n",
              "      <td>190</td>\n",
              "      <td>194</td>\n",
              "      <td>196</td>\n",
              "      <td>197</td>\n",
              "      <td>200</td>\n",
              "      <td>202</td>\n",
              "      <td>204</td>\n",
              "      <td>206</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>...</td>\n",
              "      <td>93</td>\n",
              "      <td>52</td>\n",
              "      <td>24</td>\n",
              "      <td>53</td>\n",
              "      <td>63</td>\n",
              "      <td>33</td>\n",
              "      <td>41</td>\n",
              "      <td>51</td>\n",
              "      <td>48</td>\n",
              "      <td>45</td>\n",
              "      <td>49</td>\n",
              "      <td>55</td>\n",
              "      <td>149</td>\n",
              "      <td>150</td>\n",
              "      <td>150</td>\n",
              "      <td>148</td>\n",
              "      <td>147</td>\n",
              "      <td>151</td>\n",
              "      <td>124</td>\n",
              "      <td>82</td>\n",
              "      <td>84</td>\n",
              "      <td>81</td>\n",
              "      <td>69</td>\n",
              "      <td>81</td>\n",
              "      <td>111</td>\n",
              "      <td>103</td>\n",
              "      <td>84</td>\n",
              "      <td>75</td>\n",
              "      <td>53</td>\n",
              "      <td>28</td>\n",
              "      <td>26</td>\n",
              "      <td>40</td>\n",
              "      <td>64</td>\n",
              "      <td>48</td>\n",
              "      <td>29</td>\n",
              "      <td>46</td>\n",
              "      <td>49</td>\n",
              "      <td>46</td>\n",
              "      <td>46</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      6     149     149     150  ...       106       112       120       107\n",
              "1      5     126     128     131  ...       184       184       182       180\n",
              "2     10      85      88      92  ...       226       225       224       222\n",
              "3      0     203     205     207  ...       230       240       253       255\n",
              "4      3     188     191     193  ...        49        46        46        53\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MC_sBGLekim"
      },
      "source": [
        "# extract train and test data\n",
        "\n",
        "X_train = data_train.drop('label', axis=1).values\n",
        "X_test = data_test.drop('label', axis=1).values\n",
        "y_train = data_train['label'].values\n",
        "y_test = data_test['label'].values"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Weg_z-P3e_Q9"
      },
      "source": [
        "# Label Binarizer\n",
        "lb = LabelBinarizer()\n",
        "\n",
        "y_train = lb.fit_transform(y_train)\n",
        "y_test = lb.fit_transform(y_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkBNiWHPahiJ"
      },
      "source": [
        "# normalization\n",
        "\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tissA1DvasPB"
      },
      "source": [
        "# reshape\n",
        "\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDatyOaDYeLS"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxbb5LUIYcm0"
      },
      "source": [
        "data_gen = ImageDataGenerator(\n",
        "    featurewise_center=False,\n",
        "    samplewise_center=False,\n",
        "    featurewise_std_normalization=False, \n",
        "    samplewise_std_normalization=False,\n",
        "    zca_whitening=False,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False\n",
        ")\n",
        "\n",
        "data_gen.fit(X_train)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEsOMyzwcB8n"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D6tJ9l-b8oL"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(75, (3, 3), strides=1, padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(50, (3, 3), strides=1, padding='same', activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
        "\n",
        "model.add(Conv2D(25, (3, 3), strides=1, padding='same', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=24, activation='softmax'))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVbbg-wPd_cu"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8RpEMJCedRF",
        "outputId": "5fcc6d8b-8f0f-42a2-add7-a7ff48ca9bca"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 75)        750       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 28, 28, 75)        300       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 75)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 50)        33800     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 14, 14, 50)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 14, 14, 50)        200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 50)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 25)          11275     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 7, 7, 25)          100       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 25)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               205312    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 24)                12312     \n",
            "=================================================================\n",
            "Total params: 264,049\n",
            "Trainable params: 263,749\n",
            "Non-trainable params: 300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4_c5zKVeh-y"
      },
      "source": [
        "# set parameters\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.5, min_lr=0.00001)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYg2elaZgMG9",
        "outputId": "875948cb-7214-4ad3-8a8a-9386b7b7104f"
      },
      "source": [
        "model.fit(data_gen.flow(X_train, y_train, batch_size=128), epochs=20, validation_data=(X_test, y_test), callbacks=[learning_rate_reduction])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "215/215 [==============================] - 38s 35ms/step - loss: 1.6372 - accuracy: 0.5146 - val_loss: 4.5067 - val_accuracy: 0.0608\n",
            "Epoch 2/20\n",
            "215/215 [==============================] - 7s 32ms/step - loss: 0.1628 - accuracy: 0.9472 - val_loss: 1.5577 - val_accuracy: 0.5460\n",
            "Epoch 3/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0707 - accuracy: 0.9779 - val_loss: 0.1196 - val_accuracy: 0.9572\n",
            "Epoch 4/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0406 - accuracy: 0.9864 - val_loss: 0.0870 - val_accuracy: 0.9727\n",
            "Epoch 5/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0215 - accuracy: 0.9934 - val_loss: 0.0884 - val_accuracy: 0.9697\n",
            "Epoch 6/20\n",
            "215/215 [==============================] - 7s 32ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.1243 - val_accuracy: 0.9527\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 7/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0109 - accuracy: 0.9970 - val_loss: 0.0150 - val_accuracy: 0.9950\n",
            "Epoch 8/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0136 - val_accuracy: 0.9954\n",
            "Epoch 9/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 0.0284 - val_accuracy: 0.9900\n",
            "Epoch 10/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0060 - accuracy: 0.9979 - val_loss: 0.0200 - val_accuracy: 0.9958\n",
            "Epoch 11/20\n",
            "215/215 [==============================] - 7s 34ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0214 - val_accuracy: 0.9915\n",
            "Epoch 12/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0062 - accuracy: 0.9980 - val_loss: 0.0255 - val_accuracy: 0.9921\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 13/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 0.0082 - val_accuracy: 0.9971\n",
            "Epoch 14/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0060 - val_accuracy: 0.9972\n",
            "Epoch 15/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0254 - val_accuracy: 0.9900\n",
            "Epoch 16/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0152 - val_accuracy: 0.9950\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 17/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0078 - val_accuracy: 0.9971\n",
            "Epoch 18/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0121 - val_accuracy: 0.9960\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 19/20\n",
            "215/215 [==============================] - 7s 33ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0121 - val_accuracy: 0.9961\n",
            "Epoch 20/20\n",
            "215/215 [==============================] - 7s 32ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0073 - val_accuracy: 0.9974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f9551c9cb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN3sb75AhtdK",
        "outputId": "9e2c306a-2fcb-429b-c426-3cfd4dd8d65a"
      },
      "source": [
        "# check final accuracy\n",
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "225/225 [==============================] - 1s 2ms/step - loss: 0.0073 - accuracy: 0.9974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0073227835819125175, 0.997350811958313]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExjBzyM4h5Vs"
      },
      "source": [
        "## Save predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZp68ND_h4sL",
        "outputId": "e030434b-9821-49ac-d94f-fd0c361f1a02"
      },
      "source": [
        "predictions = model.predict_classes(X_test)\n",
        "for i in range(len(predictions)):\n",
        "    if (predictions[i] >=9  or predictions[i] >= 25):\n",
        "        predictions[i] += 1\n",
        "\n",
        "predictions[:5]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  5, 10,  0,  3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5wKS5NZipsU"
      },
      "source": [
        "# save model\n",
        "\n",
        "model.save('hand_gesture1.h5')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrqZP5PBi3I0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}